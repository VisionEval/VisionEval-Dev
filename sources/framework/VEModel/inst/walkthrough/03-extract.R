### extract.R
#   Examples of retrieving raw data from a finished model run

require(VEModel) # just in case it's not already out there...
mwr <- openModel("VERSPM-run") # Run Install.R to install/run that model

##########################  
# EXTRACTING MODEL RESULTS
##########################

# "Extraction" means pulling out some or all of the raw data generated by a VisionEval
# model. If you want to get summary performance metrics from a model's results, look at
# "queries.R" Generally, you'll "extract" the results if you plan to use another program
# to analyze the raw data. (e.g. Access, Excel, Tableau, PowerBI, etc.).

# Dump all of a model's results:
results <- mwr$results()
print(results)

# You can get a list of all the results in the "Datastore" (where
# VisionEval puts its computations)
datastore.list <- results$list() # default is to show the Group/Table/Name list
print(length(datastore.list))    # number of fields in the results

 # There are a lot of fields, just show a sample. Run this command
 # multiple times to see a different sample each time.
print(datastore.list[sample(length(datastore.list),10)])

# Here are all the fields available to describe each field
# (see how to use it below in DisplayUnits example)
datastore.full.list <- results$list(details=TRUE)
print(names(datastore.full.list))
print(datastore.full.list[sample(nrow(datastore.full.list),10),])

# Compare the model list function to the results list function
# The model list reports what is in the model SPECIFICATIONS (i.e. "in theory")
# the results list reports what is in the Datastore after a run (i.e. "in reality")
# if the model crashed before completion, the two lists will be different!
modelspecs.full.list <- mwr$list(details=TRUE)
print(names(modelspecs.full.list))
print(modelspecs.full.list[sample(nrow(modelspecs.full.list),10),])

# Remember that you can open (or extract) the model results even if something went wrong during a
# run - the results list will show you the subset of data that got computed before the model
# crashed. Look for the section on "debuggint" at https://visioneval.org/docs

# Result extraction must be done stage-by-stage (or scenario-by-scenario)
# See "model-stages.R" and "scenarios.R" walkthrough for how to manage stages
# (including dumping all the raw scenario data into a - possibly huge - database)

# Queries, on the other hand, work just fine with scenarios and modelStages
# (that is, you just run the query on the results and it will process every Reportable stage).
# See the "07-queries.R" walkthrough.

# Here's the basic extraction of everything in the final Reportable model stage
results$extract()
mwr$dir(output=TRUE)                # Just shows the sub-directory names holding outputs

outputs <- mwr$dir(output=TRUE,all.files=TRUE) # Lists all the extracted output files
print(outputs)

# Inspect one of the metadata files. Metadata is very basic: just the field
# group/table/name and units (plus display units if those are different, see below)
metadata.HH2038 <- read.csv( file=grep("2038_Household.*metadata\\.csv",outputs,value=TRUE))
metadata.HH2038[1:10,]

# You can select certain Groups (e.g. just the Years), Tables and Files rather than
# extracting everything.

# First, just show what's out there
# The Group can be an actual Year, otherwise "Year" will expand to all the Years
# for which the model was run.
wkr <- results$find(Group="Year",Table="Worker")
print(wkr)
print(wkr$fields()) # same...

# Provide a list of table names to find
# Can also do that with Group or Field
# Will get both tables in all Groups (unless you select a specific Group)
wkr.veh <- results$find(Table=c("Worker","Vehicle"))
print(wkr.veh)
rm(wkr.veh)

results$select( wkr ) # filters results on selected fields
print(results) # Just the Worker tables selected

results$select( wkr.veh )
print(results) # Worker and Vehicle tables

results$select() # clear selection (selects all)
print(results) # Everything selected againg

# "all-in-one" instruction to find and select fields at once
results$find(Group="Year",Table=c("Worker","Vehicle",select=TRUE)
print(results) # Just the Worker tables selected

results$extract()  # just extract Worker and Vehicle Tables in each year

# There are much more nuanced selection features available, see https://visioneval.org/docs

###################
# CLEARING EXTRACTS
###################

# Here are instructions for cleaning up old extracts from within R
# You can always delete them using regular operating system commands (File Explorer / Finder)

mwr$dir(outputs=TRUE) # Show all the output folders we created by extracting above
mwr$clear()           # By default, will offer to clear any outputs; can also clear current or saved model results
# Choose "all" to delete all outputs, or you can select them by number or range
mwr$dir(outputs=TRUE,all.files=TRUE) # in case you forgot what is in each extraction folder...

###########################
# SELECTING A FIELD PATTERN
###########################

# The following uses a "selection" to navigate results

# Select fields using a "pattern" (R regular expression applied just to the field name)
selected <- results$find(pattern="speed",Group="Year",Table=c("Household","Vehicle","Marea","Bzone"))
print(selectedf$fields()) # only fields that have "speed" in their name

########################
# CHANGING DISPLAY UNITS
########################

# You can create a file called "display_units.csv" and put it in your
# model's "defs" folder. Then the fields listed there can have their
# units automatically converted when you extract them.

# Programatically set up the display_units file with a useful conversion
# This shows how to construct a DisplayUnitsFile
# Practically speaking, you can do this once in your life and drop it
# into your model's "defs" directory.
un <- results$list(details=TRUE)[,c("Group","Table","Name","Units")]
spd <- un[ grepl("MI/",un$Units)&grepl("sp",un$Name,ignore.case=TRUE), ]
spd$DisplayUnits <- "MI/HR"
print(spd)

# Put the display_units file in a useful place (model 'defs' folder)
# This file will be automatically used during export!
display_units_file <- file.path(
  mwr$modelPath,           # folder for model, inside the "models" folder
  mwr$setting("ParamDir"), # "defs" by default
  mwr$setting("DisplayUnitsFile") # defaults to 'display_units.csv'
)
cat(display_units_file,"\n")
write.csv(spd,file=display_units_file,row.names=FALSE)

# Select speed fields...
# We'll construct a list of Datastore speed-related field names using the
#  fields we found from the results$list() function above
# Or as we saw before, we could probe around in the results directly.

# Get a selection attached to the results
selected <- results$select()

selected$select( with(spd,paste(Group,Table,Name,sep="/")) ) # select the speed fields
print(selected) # All of them happen to be in the Marea Table

selected$all() # re-select everything
print(selected)

# Could do the following instead
selected$find(pattern="speed",select=TRUE)
print(selected)

# Showing currently defined UNITS/DISPLAYUNITS (via selection)
print(selected$results$units())

# Showing currently defined UNITS/DISPLAYUNITS (directly from results)
print(results$units())

###################
# ADDING KEY FIELDS
###################

# Because we only included the "good stuff" (speed fields), we should
# add back in the Table key fields (which Marea and Bzone for each row)

# We could manually add the geography fields in the Marea Table
# (Useful if you already know exactly which you need)
geoFields <- selected$find("^Marea$",Group="Years",Table="Marea")
print(geoFields)

# There's a shortcut for adding the primary and foreign key fields to each Table
# Useful if you just want something that will work with your external database
# And especially useful if you don't happen to know what the key fields are in each Table!
print(selected$fields())  # the "good stuff"
selected$addkeys() # Only operates on tables that are already selected and ignores tables that are not
print(selected$fields())  # now with added key fields
print(results$units()) # Units for the results...

# Extracting speed fields using DISPLAY units ("prefix" adjusts the extracted results file name)
selected$extract(prefix="DisplayUnits")                 # Using DISPLAY units

# Extract speed fields using DATASTORE units
# Note: "export" is the same (for now) as "extract"
# Eventually, "extract" will always produce a list of data.frames, and "export" will save it
selected$extract(prefix="Datastore",convertUnits=FALSE)  # Using DATASTORE units

# In general, it is better to use queries to do the extraction and unit conversion
# since you may confuse yourself when you load up the extracted raw data into your
# other database... See "05-queries.R" later in this walkthrough.

#############################
# EXTRACTING AS R DATA.FRAMES
#############################

# Reset the selection to something useful
slf <- results$find(pattern="speed",Group="Year",Table=c("Household","Vehicle","Marea","Bzone"))
print(slf)
slf$addkeys() # Add table key fields (see below)
print(slf)    # Note that it now contains Marea as key

# extract can produce a list of R data.frames instead of .csv files
# you can save those in any file format that can understand a table of rows and columns
extracted.df <- slf$extract(saveTo=FALSE)
# returns a named list of data.frames whose names correspond to the tables
print(names(extracted.df))
print(names(extracted.df$`2010.Marea`)) # note quotes around "numeric" Group.Table name

# you can also get data.frames with the metadata for each field (rather than the data)
meta.df <- slf$extract(saveTo=FALSE,data=FALSE)
print(names(meta.df[[1]]))    # Columns are the metadata fields
print(meta.df[[1]][1:10,])    # Rows are the individual data element names and their metadata values

####################################
# EXTRACTING TO AN EXTERNAL DATABASE
####################################

# Note that the following general concept will work with ANY R DBI compliant datasource,
# so you can use Excel (if the tables don't have too many rows) or Access, or SQLServer or
# Oracle or PostgreSQL or ... whatever! Just change the db.connection (see the R DBI
# documentation and the package docs for your particular database). You may have to tinker
# with Excel to get the Workbook/Worksheets to come out right...

require(RSQLite)  # you may need to install RSQLite and its dependencies
# There are also R packages to write Excel, Access, or whatever
# You can use any of them that can write a data.frame

# Make a temporary SQLite database
# Use the "setting" function to locate the "outputs" directory
db.connection <- file.path(results$resultsPath,mwr$setting("OutputDir"),"my-db.sqlite")

# You can choose to overwrite either by deleting the database like this...
# if ( file.exists(db.connection) ) unlink(db.connection)

# Or you can open the database with overwrite=TRUE
# db.connection <- file.path(results$resultsPath,mwr$setting("OutputDir"),"my-db.sqlite",overwrite=TRUE)

mydb <- DBI::dbConnect(RSQLite::SQLite(), db.connection)

# Put the extracted data into tables in the new database
# Each table has the same name as the extracted data.frame
# If the table already exists, overwrite=TRUE says to overwrite it, otherwise an error
for ( ve.table in names(extracted.df) ) {
  dbWriteTable( mydb, ve.table, extracted.df[[ve.table]], overwrite=TRUE )
}

# See the tables in the database
DBI::dbListTables(mydb)

# Or you can visit the database with an outside utility (e.g. HeidiSQL)

# It's good practice to close the database when you're done with it
DBI::dbDisconnect(mydb)
